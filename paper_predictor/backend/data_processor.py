#!/usr/bin/env python3
"""
çœŸå®æ•°æ®é¢„å¤„ç†è„šæœ¬
å°†ä½ çš„çœŸå®ICLRæ•°æ®è½¬æ¢ä¸ºç³»ç»Ÿå¯ç”¨æ ¼å¼

ä½¿ç”¨æ–¹æ³•ï¼š
1. å°†ä½ çš„ example.json (æˆ–å…¶ä»–åŸå§‹æ•°æ®æ–‡ä»¶) æ”¾åœ¨é¡¹ç›®ç›®å½•
2. è¿è¡Œ: python data_processor.py example.json nips_history_data/ICLR_2024_formatted.jsonl
3. é‡å¯åç«¯æœåŠ¡å³å¯ä½¿ç”¨çœŸå®æ•°æ®
"""

import json
import os
import sys
from pathlib import Path


def process_review_data(raw_data_file, output_file):
    """
    å¤„ç†çœŸå®è¯„å®¡æ•°æ®

    Args:
        raw_data_file: åŸå§‹æ•°æ®æ–‡ä»¶è·¯å¾„ (å¦‚ example.json)
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ (å¦‚ ICLR_2024_formatted.jsonl)
    """

    print(f"ğŸ”„ å¤„ç†æ•°æ®æ–‡ä»¶: {raw_data_file}")

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_path = Path(output_file)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    processed_count = 0
    valid_papers = 0

    try:
        # åˆ¤æ–­è¾“å…¥æ–‡ä»¶æ ¼å¼
        if raw_data_file.endswith('.jsonl'):
            # JSONLæ ¼å¼ - æ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡
            with open(raw_data_file, 'r', encoding='utf-8') as infile:
                papers = []
                for line in infile:
                    line = line.strip()
                    if line:
                        papers.append(json.loads(line))
        else:
            # å•ä¸ªJSONæ–‡ä»¶
            with open(raw_data_file, 'r', encoding='utf-8') as infile:
                data = json.load(infile)
                # å¦‚æœæ˜¯å•ä¸ªè®ºæ–‡å¯¹è±¡ï¼ŒåŒ…è£…æˆåˆ—è¡¨
                if isinstance(data, dict):
                    papers = [data]
                else:
                    papers = data

        print(f"ğŸ“Š å‘ç° {len(papers)} ç¯‡è®ºæ–‡")

        # å¤„ç†æ¯ç¯‡è®ºæ–‡
        with open(output_file, 'w', encoding='utf-8') as outfile:
            for paper in papers:
                processed_paper = process_single_paper(paper)
                if processed_paper:
                    outfile.write(json.dumps(processed_paper, ensure_ascii=False) + '\n')
                    valid_papers += 1
                processed_count += 1

                # æ˜¾ç¤ºè¿›åº¦
                if processed_count % 100 == 0:
                    print(f"â³ å·²å¤„ç† {processed_count}/{len(papers)} ç¯‡è®ºæ–‡...")

    except Exception as e:
        print(f"âŒ å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return False

    print(f"âœ… æ•°æ®å¤„ç†å®Œæˆ!")
    print(f"   - æ€»æ•°æ®: {processed_count} ç¯‡")
    print(f"   - æœ‰æ•ˆæ•°æ®: {valid_papers} ç¯‡")
    print(f"   - è¾“å‡ºæ–‡ä»¶: {output_file}")

    # åˆ†ææ•°æ®è´¨é‡
    analyze_processed_data(output_file)

    return True


def process_single_paper(paper_data):
    """
    å¤„ç†å•ç¯‡è®ºæ–‡æ•°æ®

    Args:
        paper_data: åŸå§‹è®ºæ–‡æ•°æ®

    Returns:
        dict: æ ¼å¼åŒ–åçš„è®ºæ–‡æ•°æ®ï¼Œå¦‚æœæ•°æ®æ— æ•ˆè¿”å›None
    """

    try:
        # æå–åŸºæœ¬ä¿¡æ¯
        paper_title = paper_data.get('paper_title', 'Unknown Title')
        paper_authors = paper_data.get('paper_authors', [])
        paper_abstract = paper_data.get('paper_abstract', '')
        paper_keywords = paper_data.get('paper_keywords', [])
        paper_tldr = paper_data.get('paper_tldr', '')
        paper_track = paper_data.get('paper_track', 'general')
        paper_venue = paper_data.get('paper_venue', 'ICLR 2024')
        paper_decision = paper_data.get('paper_decision', 'Unknown')

        # å¤„ç†è¯„å®¡æ•°æ®
        reviews = paper_data.get('reviews', [])
        processed_reviews = []

        for review in reviews:
            # è·³è¿‡æ— æ•ˆè¯„å®¡
            if not review or not isinstance(review, dict):
                continue

            # æå–è¯„åˆ†å’Œè‡ªä¿¡å¿ƒ
            rating = review.get('rating', '-1')
            confidence = review.get('confidence', '-1')
            reviewer = review.get('reviewer', '')

            # å¤„ç†å¯¹è¯æ•°æ®
            dialogue = review.get('dialogue', [])

            processed_review = {
                "reviewer": reviewer,
                "rating": str(rating),
                "confidence": str(confidence),
                "dialogue": dialogue
            }

            processed_reviews.append(processed_review)

        # å¦‚æœæ²¡æœ‰æœ‰æ•ˆè¯„å®¡ï¼Œè·³è¿‡è¿™ç¯‡è®ºæ–‡
        if not processed_reviews:
            return None

        # æ„å»ºæœ€ç»ˆæ•°æ®ç»“æ„
        formatted_paper = {
            "paper_title": paper_title,
            "paper_authors": paper_authors if isinstance(paper_authors, list) else [str(paper_authors)],
            "paper_abstract": paper_abstract,
            "paper_keywords": paper_keywords if isinstance(paper_keywords, list) else [str(paper_keywords)],
            "paper_tldr": paper_tldr,
            "paper_track": paper_track,
            "paper_venue": paper_venue,
            "paper_decision": paper_decision,
            "reviews": processed_reviews
        }

        return formatted_paper

    except Exception as e:
        print(f"âš ï¸  å¤„ç†è®ºæ–‡æ—¶å‡ºé”™: {e}")
        return None


def analyze_processed_data(data_file):
    """
    åˆ†æå¤„ç†åçš„æ•°æ®è´¨é‡
    """

    print(f"\nğŸ“ˆ æ•°æ®è´¨é‡åˆ†æ: {data_file}")
    print("=" * 50)

    try:
        papers = []
        with open(data_file, 'r', encoding='utf-8') as f:
            for line in f:
                papers.append(json.loads(line.strip()))

        if not papers:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆæ•°æ®")
            return

        # åŸºæœ¬ç»Ÿè®¡
        total_papers = len(papers)
        accepted_papers = sum(1 for p in papers if 'accept' in p.get('paper_decision', '').lower())
        rejected_papers = sum(1 for p in papers if 'reject' in p.get('paper_decision', '').lower())
        acceptance_rate = accepted_papers / total_papers if total_papers > 0 else 0

        print(f"ğŸ“Š è®ºæ–‡æ€»æ•°: {total_papers}")
        print(f"âœ… æ¥æ”¶è®ºæ–‡: {accepted_papers} ({acceptance_rate:.1%})")
        print(f"âŒ æ‹’ç»è®ºæ–‡: {rejected_papers} ({(1 - acceptance_rate):.1%})")

        # è¯„å®¡ç»Ÿè®¡
        all_scores = []
        all_confidences = []
        review_counts = []

        for paper in papers:
            reviews = paper.get('reviews', [])
            review_counts.append(len(reviews))

            for review in reviews:
                rating = review.get('rating', '-1')
                confidence = review.get('confidence', '-1')

                if rating != '-1':
                    try:
                        score = float(rating)
                        if 1 <= score <= 10:
                            all_scores.append(score)
                    except:
                        pass

                if confidence != '-1':
                    try:
                        conf = float(confidence)
                        if 1 <= conf <= 5:
                            all_confidences.append(conf)
                    except:
                        pass

        print(f"\nğŸ“ è¯„å®¡ç»Ÿè®¡:")
        print(f"   - å¹³å‡è¯„å®¡æ•°/è®ºæ–‡: {sum(review_counts) / len(review_counts):.1f}")
        print(f"   - æœ‰æ•ˆè¯„åˆ†æ•°: {len(all_scores)}")
        print(f"   - è¯„åˆ†èŒƒå›´: {min(all_scores):.1f} - {max(all_scores):.1f}")
        print(f"   - å¹³å‡è¯„åˆ†: {sum(all_scores) / len(all_scores):.2f}")

        if all_confidences:
            print(f"   - æœ‰æ•ˆè‡ªä¿¡å¿ƒæ•°: {len(all_confidences)}")
            print(f"   - å¹³å‡è‡ªä¿¡å¿ƒ: {sum(all_confidences) / len(all_confidences):.2f}")

        # è¯„åˆ†åˆ†å¸ƒ
        score_distribution = {}
        for score in all_scores:
            score_int = int(score)
            score_distribution[score_int] = score_distribution.get(score_int, 0) + 1

        print(f"\nğŸ“Š è¯„åˆ†åˆ†å¸ƒ:")
        for score in sorted(score_distribution.keys()):
            count = score_distribution[score]
            percentage = count / len(all_scores) * 100
            print(f"   - è¯„åˆ† {score}: {count} ({percentage:.1f}%)")

    except Exception as e:
        print(f"âŒ åˆ†ææ•°æ®æ—¶å‡ºé”™: {e}")


def batch_process_files(input_dir, output_dir):
    """
    æ‰¹é‡å¤„ç†å¤šä¸ªæ•°æ®æ–‡ä»¶
    """

    input_path = Path(input_dir)
    output_path = Path(output_dir)

    if not input_path.exists():
        print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        return

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_path.mkdir(parents=True, exist_ok=True)

    # æŸ¥æ‰¾æ‰€æœ‰JSON/JSONLæ–‡ä»¶
    json_files = list(input_path.glob("*.json")) + list(input_path.glob("*.jsonl"))

    if not json_files:
        print(f"âŒ åœ¨ {input_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°JSONæ–‡ä»¶")
        return

    print(f"ğŸ” å‘ç° {len(json_files)} ä¸ªæ•°æ®æ–‡ä»¶")

    for json_file in json_files:
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        output_file = output_path / f"{json_file.stem}_formatted.jsonl"

        print(f"\n{'=' * 60}")
        success = process_review_data(str(json_file), str(output_file))

        if not success:
            print(f"âŒ å¤„ç†å¤±è´¥: {json_file}")


def main():
    """ä¸»å‡½æ•°"""

    print("ğŸ¯ ICLRè®ºæ–‡æ•°æ®é¢„å¤„ç†å·¥å…·")
    print("=" * 50)

    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) < 2:
        print("ğŸ“– ä½¿ç”¨æ–¹æ³•:")
        print("   å•æ–‡ä»¶: python data_processor.py <input_file> [output_file]")
        print("   æ‰¹é‡å¤„ç†: python data_processor.py --batch <input_dir> [output_dir]")
        print("")
        print("ğŸ’¡ ç¤ºä¾‹:")
        print("   python data_processor.py example.json ICLR_2024_formatted.jsonl")
        print("   python data_processor.py --batch raw_data/ nips_history_data/")
        return

    if sys.argv[1] == "--batch":
        # æ‰¹é‡å¤„ç†æ¨¡å¼
        if len(sys.argv) < 3:
            print("âŒ æ‰¹é‡å¤„ç†éœ€è¦æŒ‡å®šè¾“å…¥ç›®å½•")
            return

        input_dir = sys.argv[2]
        output_dir = sys.argv[3] if len(sys.argv) > 3 else "nips_history_data"

        batch_process_files(input_dir, output_dir)

    else:
        # å•æ–‡ä»¶å¤„ç†æ¨¡å¼
        input_file = sys.argv[1]

        if not os.path.exists(input_file):
            print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
            return

        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        if len(sys.argv) > 2:
            output_file = sys.argv[2]
        else:
            # è‡ªåŠ¨ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            base_name = Path(input_file).stem
            output_file = f"nips_history_data/{base_name}_formatted.jsonl"

        process_review_data(input_file, output_file)

    print(f"\nğŸ‰ å¤„ç†å®Œæˆï¼")
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶å·²ä¿å­˜åˆ°æŒ‡å®šä½ç½®")
    print(f"ğŸš€ ç°åœ¨å¯ä»¥å¯åŠ¨APIæœåŠ¡å™¨æµ‹è¯•é¢„æµ‹åŠŸèƒ½äº†ï¼")


if __name__ == "__main__":
    main()