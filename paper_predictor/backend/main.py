from fastapi import FastAPI, HTTPException, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from typing import List, Optional
import uvicorn
import os
import shutil
import json
import uuid
import time
import numpy as np
from datetime import datetime
import random
import requests

app = FastAPI(
    title="è®ºæ–‡æ¥å—ç‡é¢„æµ‹API",
    description="åŸºäºè§„åˆ™ç®—æ³•çš„è®ºæ–‡æ¥å—ç‡é¢„æµ‹ç³»ç»Ÿ",
    version="2.0.0"
)

# åˆ›å»ºç›®å½•
os.makedirs("uploads/qr_codes", exist_ok=True)
os.makedirs("data", exist_ok=True)
os.makedirs("nips_history_data", exist_ok=True)  # å†å²æ•°æ®ç›®å½•

# ä¿®å¤1ï¼šæ›´çµæ´»çš„CORSé…ç½® - æ”¯æŒéƒ¨ç½²ç¯å¢ƒ
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",  # æœ¬åœ°å¼€å‘
        "http://127.0.0.1:3000",  # æœ¬åœ°å¼€å‘
        "https://products-silk-chi.vercel.app",  # ğŸ”¥ ä½ çš„Vercelå‰ç«¯URL
        "https://*.vercel.app",  # æ‰€æœ‰Vercelå­åŸŸå
        "*"  # ä¸´æ—¶å…è®¸æ‰€æœ‰åŸŸåï¼Œç”Ÿäº§ç¯å¢ƒå»ºè®®é™åˆ¶
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# é™æ€æ–‡ä»¶æœåŠ¡
app.mount("/uploads", StaticFiles(directory="uploads"), name="uploads")

# å…¨å±€è®¾ç½®å­˜å‚¨
SETTINGS_FILE = "data/settings.json"
PAYMENTS_FILE = "data/payments.json"

# é»˜è®¤è®¾ç½®
DEFAULT_SETTINGS = {
    "price": 0.2,
    "qr_code_url": "",
    "contact_phone": "13109973548",
    "score_options": [1, 3, 5, 6, 8, 10],
    "confidence_options": [1, 2, 3, 4, 5],
    "conference": "ICLR",
    "year": "2024",
    "payment_wait_time": 60  # æ–°å¢ï¼šæ”¯ä»˜ç­‰å¾…æ—¶é—´
}

# æ”¯ä»˜è®¢å•å­˜å‚¨
payments = {}

# é¢„æµ‹ç»Ÿè®¡
prediction_stats = {
    "total_predictions": 0,
    "avg_prediction_time": 0
}

# Google Driveä¸‹è½½é“¾æ¥
ICLR_2024_URL = "https://drive.google.com/uc?export=download&id=1CVsi7YU6rNcrhNqPMrGOWsxqHpsmysH4"
ICLR_2025_URL = "https://drive.google.com/uc?export=download&id=1NXYIG-UIQUnur24fe36fqaobl722pCr_"

# æœ¬åœ°æ–‡ä»¶è·¯å¾„
ICLR_2024_FILE = "nips_history_data/ICLR_2024_formatted.jsonl"
ICLR_2025_FILE = "nips_history_data/ICLR_2025_formatted.jsonl"


def download_data_from_google_drive():
    """ä»Google Driveä¸‹è½½æ•°æ®æ–‡ä»¶ï¼ˆä»…åœ¨æœåŠ¡å™¨å¯åŠ¨æ—¶æ‰§è¡Œä¸€æ¬¡ï¼‰"""

    # Google Driveä¸‹è½½é“¾æ¥
    files_to_download = {
        "nips_history_data/ICLR_2024_formatted.jsonl": "https://drive.google.com/uc?export=download&id=1CVsi7YU6rNcrhNqPMrGOWsxqHpsmysH4",
        "nips_history_data/ICLR_2025_formatted.jsonl": "https://drive.google.com/uc?export=download&id=1NXYIG-UIQUnur24fe36fqaobl722pCr_"
    }

    print("ğŸŒ æ£€æŸ¥å†å²æ•°æ®æ–‡ä»¶...")

    for file_path, download_url in files_to_download.items():
        if not os.path.exists(file_path):
            print(f"ğŸ“¥ ä¸‹è½½ {file_path}...")
            try:
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                }
                response = requests.get(download_url, timeout=600, stream=True, headers=headers, allow_redirects=True)
                response.raise_for_status()

                # ç¡®ä¿ç›®å½•å­˜åœ¨
                os.makedirs(os.path.dirname(file_path), exist_ok=True)

                # ä¿å­˜æ–‡ä»¶
                with open(file_path, 'wb') as f:
                    f.write(response.content)

                print(f"âœ… {file_path} ä¸‹è½½æˆåŠŸ ({len(response.content) / 1024 / 1024:.1f} MB)")

            except Exception as e:
                print(f"âŒ {file_path} ä¸‹è½½å¤±è´¥: {e}")
        else:
            print(f"âœ… {file_path} å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")


# å…¨å±€å†å²æ•°æ®ç¼“å­˜
historical_data = {}


def load_historical_data():
    """åŠ è½½å†å²è¯„å®¡æ•°æ®"""
    global historical_data
    print("ğŸ“Š å¼€å§‹åŠ è½½å†å²æ•°æ®...")
    print("ğŸ” å½“å‰å·¥ä½œç›®å½•:", os.getcwd())
    print("ğŸ” æ£€æŸ¥æ–‡ä»¶å­˜åœ¨:")
    for year, file_path in [("2024", ICLR_2024_FILE), ("2025", ICLR_2025_FILE)]:
        exists = os.path.exists(file_path)
        if exists:
            size = os.path.getsize(file_path)
            print(f"  âœ… {file_path}: {size/1024/1024:.1f}MB")
        else:
            print(f"  âŒ {file_path}: ä¸å­˜åœ¨")

    for year, file_path in [("2024", ICLR_2024_FILE), ("2025", ICLR_2025_FILE)]:
        if os.path.exists(file_path):
            try:
                papers = []
                print(f"ğŸ“– è¯»å–æ–‡ä»¶: {file_path}")

                with open(file_path, 'r', encoding='utf-8') as f:
                    for line_num, line in enumerate(f, 1):
                        line = line.strip()
                        if line:
                            try:
                                paper = json.loads(line)
                                papers.append(paper)
                            except json.JSONDecodeError as e:
                                print(f"âš ï¸  è·³è¿‡ç¬¬{line_num}è¡Œï¼ŒJSONè§£æé”™è¯¯: {e}")
                                continue

                if not papers:
                    print(f"âŒ {file_path} æ²¡æœ‰æœ‰æ•ˆæ•°æ®")
                    continue

                # è®¡ç®—æ¯ç¯‡è®ºæ–‡çš„å¹³å‡åˆ†å¹¶åˆ†ç±»
                all_papers_with_avg = []
                accepted_papers_with_avg = []

                for paper in papers:
                    scores = extract_paper_scores(paper)
                    if scores:  # åªå¤„ç†æœ‰è¯„åˆ†çš„è®ºæ–‡
                        avg_score = np.mean(scores)
                        paper_with_avg = {
                            'avg_score': avg_score,
                            'scores': scores,
                            'decision': paper.get('paper_decision', '').lower()
                        }
                        all_papers_with_avg.append(paper_with_avg)

                        # åˆ¤æ–­æ˜¯å¦è¢«æ¥å—
                        decision = paper.get('paper_decision', '').lower()
                        if 'accept' in decision:
                            accepted_papers_with_avg.append(paper_with_avg)

                # æŒ‰å¹³å‡åˆ†é™åºæ’åº
                all_papers_with_avg.sort(key=lambda x: x['avg_score'], reverse=True)
                accepted_papers_with_avg.sort(key=lambda x: x['avg_score'], reverse=True)

                historical_data[year] = {
                    "all_papers": all_papers_with_avg,
                    "accepted_papers": accepted_papers_with_avg,
                    "total_count": len(all_papers_with_avg),
                    "accepted_count": len(accepted_papers_with_avg),
                    "acceptance_rate": len(accepted_papers_with_avg) / len(
                        all_papers_with_avg) if all_papers_with_avg else 0
                }

                print(
                    f"âœ… {year} å¹´æ•°æ®: {len(all_papers_with_avg)} ç¯‡æœ‰æ•ˆè®ºæ–‡, æ¥å— {len(accepted_papers_with_avg)} ç¯‡, æ¥å—ç‡ {historical_data[year]['acceptance_rate']:.2%}")

            except Exception as e:
                print(f"âŒ åŠ è½½ {year} å¹´æ•°æ®å¤±è´¥: {e}")
        else:
            print(f"âš ï¸  æœªæ‰¾åˆ° {year} å¹´æ•°æ®æ–‡ä»¶: {file_path}")

    if not historical_data:
        print("âŒ æ²¡æœ‰åŠ è½½åˆ°ä»»ä½•å†å²æ•°æ®ï¼Œå°†ä½¿ç”¨é»˜è®¤ç®—æ³•")
    else:
        print(f"ğŸ‰ æˆåŠŸåŠ è½½ {len(historical_data)} å¹´çš„å†å²æ•°æ®")


def extract_paper_scores(paper):
    """ä»è®ºæ–‡æ•°æ®ä¸­æå–è¯„åˆ†ä¿¡æ¯"""
    scores = []
    if 'reviews' in paper and paper['reviews']:
        for review in paper['reviews']:
            rating = review.get('rating', '')
            rating = rating.split(':')[0]
            # è§£æè¯„åˆ†
            if rating and rating != '-1':
                try:
                    score = float(rating)
                    if 1 <= score <= 10:
                        scores.append(score)
                except:
                    pass
    return scores


def calculate_paper_ranking_basic(target_scores, target_confidences, year="2025"):
    """åŸºäºè§„åˆ™çš„è®ºæ–‡æ¥å—ç‡é¢„æµ‹"""
    print(f"ğŸ” æ”¶åˆ°é¢„æµ‹è¯·æ±‚ - è¯„åˆ†: {target_scores}, è‡ªä¿¡å¿ƒ: {target_confidences}, å¹´ä»½: {year}")

    if not target_scores:
        print("âŒ æ²¡æœ‰è¯„åˆ†æ•°æ®")
        return {
            "probability": 0.0,
            "rank_in_all": 10000,
            "rank_in_accepted": 2500,
            "total_papers": 12000,
            "accepted_papers": 3000,
            "prediction_method": "rule_threshold"
        }

    # è®¡ç®—ç”¨æˆ·è®ºæ–‡çš„åŸºæœ¬ç»Ÿè®¡
    user_avg_score = np.mean(target_scores)
    positive_scores = sum(1 for score in target_scores if score >= 5)
    negative_scores = sum(1 for score in target_scores if score < 5)

    print(f"ğŸ“Š ç”¨æˆ·è®ºæ–‡ç»Ÿè®¡ - å¹³å‡åˆ†: {user_avg_score:.2f}, æ­£åˆ†æ•°: {positive_scores}, è´Ÿåˆ†æ•°: {negative_scores}")

    # è§„åˆ™åˆ¤æ–­æ¦‚ç‡
    final_probability = 0.5  # é»˜è®¤æ¦‚ç‡

    # è§„åˆ™1: å‡å€¼ > 6
    if user_avg_score > 6:
        final_probability = random.uniform(0.85, 0.95)
        print(f"âœ… è§„åˆ™1å‘½ä¸­: å‡å€¼{user_avg_score:.2f} > 6, æ¦‚ç‡: {final_probability:.3f}")
    # è§„åˆ™2: å‡å€¼ <= 4
    elif user_avg_score <= 4:
        final_probability = random.uniform(0.01, 0.2)
        print(f"âŒ è§„åˆ™2å‘½ä¸­: å‡å€¼{user_avg_score:.2f} <= 4, æ¦‚ç‡: {final_probability:.3f}")
    # è§„åˆ™3: å…¨æ˜¯æ­£åˆ†ï¼ˆ>=5ï¼‰
    elif negative_scores == 0:
        final_probability = random.uniform(0.85, 0.95)
        print(f"âœ… è§„åˆ™3å‘½ä¸­: å…¨æ˜¯æ­£åˆ†, æ¦‚ç‡: {final_probability:.3f}")
    # è§„åˆ™4: å…¨æ˜¯è´Ÿåˆ†ï¼ˆ<5ï¼‰
    elif positive_scores == 0:
        final_probability = random.uniform(0.1, 0.25)
        print(f"âŒ è§„åˆ™4å‘½ä¸­: å…¨æ˜¯è´Ÿåˆ†, æ¦‚ç‡: {final_probability:.3f}")
    # è§„åˆ™5: è´Ÿåˆ†ä¸ªæ•° > æ­£åˆ†ä¸ªæ•°
    elif negative_scores > positive_scores:
        final_probability = random.uniform(0.1, 0.35)
        print(f"âŒ è§„åˆ™5å‘½ä¸­: è´Ÿåˆ†({negative_scores}) > æ­£åˆ†({positive_scores}), æ¦‚ç‡: {final_probability:.3f}")
    # è§„åˆ™6: ä¸‰ä¸ªæˆ–æ›´å¤šè´Ÿåˆ†
    elif negative_scores >= 3:
        final_probability = random.uniform(0.01, 0.22)
        print(f"âŒ è§„åˆ™6å‘½ä¸­: {negative_scores}ä¸ªè´Ÿåˆ†, æ¦‚ç‡: {final_probability:.3f}")
    # è§„åˆ™7: åªæœ‰ä¸€ä¸ªè´Ÿåˆ†ä¸”å‡å€¼ > 5
    elif negative_scores == 1 and user_avg_score > 5:
        final_probability = random.uniform(0.80, 0.90)
        print(f"âœ… è§„åˆ™7å‘½ä¸­: 1ä¸ªè´Ÿåˆ†ä¸”å‡å€¼{user_avg_score:.2f} > 5, æ¦‚ç‡: {final_probability:.3f}")
    # è§„åˆ™8: æœ‰ä¸¤ä¸ªè´Ÿåˆ†
    elif negative_scores == 2:
        final_probability = random.uniform(0.60, 0.75)
        print(f"âš ï¸  è§„åˆ™8å‘½ä¸­: 2ä¸ªè´Ÿåˆ†, æ¦‚ç‡: {final_probability:.3f}")
    # è§„åˆ™9: åˆ†æ•°åªæœ‰5å’Œ6
    elif all(score in [5, 6] for score in target_scores):
        final_probability = random.uniform(0.75, 0.85)
        print(f"âœ… è§„åˆ™9å‘½ä¸­: å…¨æ˜¯5,6åˆ†, æ¦‚ç‡: {final_probability:.3f}")
    # é»˜è®¤æƒ…å†µï¼šåŸºäºå‡å€¼çº¿æ€§æ’å€¼
    else:
        if user_avg_score >= 5:
            final_probability = (user_avg_score - 4) / (6 - 4) * (0.75 - 0.25) + 0.25
        else:
            final_probability = 0.25
        print(f"ğŸ“ é»˜è®¤çº¿æ€§æ’å€¼: å‡å€¼{user_avg_score:.2f}, æ¦‚ç‡: {final_probability:.3f}")

    # ä¿®å¤2ï¼šç¡®ä¿ä»æ­£ç¡®çš„å†å²æ•°æ®è®¡ç®—æ’å
    prev_year = str(int(year) - 1)  # é¢„æµ‹å¹´ä»½çš„å‰ä¸€å¹´ä½œä¸ºå‚è€ƒæ•°æ®

    if prev_year in historical_data and historical_data[prev_year]["all_papers"]:
        print(f"ğŸ“ˆ ä½¿ç”¨ {prev_year} å¹´å†å²æ•°æ®è®¡ç®—æ’å")

        all_papers = historical_data[prev_year]["all_papers"]
        accepted_papers = historical_data[prev_year]["accepted_papers"]

        # è®¡ç®—åœ¨æ‰€æœ‰è®ºæ–‡ä¸­çš„æ’åï¼šæ¯”ç”¨æˆ·å‡åˆ†é«˜çš„è®ºæ–‡æ•°é‡ + 1
        rank_in_all = 1
        for paper in all_papers:
            if paper['avg_score'] > user_avg_score:
                rank_in_all += 1
            else:
                break  # å› ä¸ºå·²ç»æŒ‰é™åºæ’åºï¼Œå¯ä»¥æå‰é€€å‡º

        # è®¡ç®—åœ¨æ¥å—è®ºæ–‡ä¸­çš„æ’å
        rank_in_accepted = 1
        for paper in accepted_papers:
            if paper['avg_score'] > user_avg_score:
                rank_in_accepted += 1
            else:
                break

        total_papers = len(all_papers)
        accepted_papers_count = len(accepted_papers)

        print(f"ğŸ† æ’åè®¡ç®—å®Œæˆ:")
        print(f"  - åœ¨æ‰€æœ‰è®ºæ–‡ä¸­: ç¬¬ {rank_in_all} å / å…± {total_papers} ç¯‡")
        print(f"  - åœ¨æ¥å—è®ºæ–‡ä¸­: ç¬¬ {rank_in_accepted} å / å…± {accepted_papers_count} ç¯‡")
        print(f"  - ç”¨æˆ·å¹³å‡åˆ† {user_avg_score:.2f} åœ¨å†å²æ•°æ®ä¸­çš„ä½ç½®")

    else:
        print(f"âš ï¸  æœªæ‰¾åˆ° {prev_year} å¹´å†å²æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤æ’å")
        # ä½¿ç”¨é»˜è®¤å€¼
        total_papers = 12000
        accepted_papers_count = 3000
        # åŸºäºæ¦‚ç‡ä¼°ç®—æ’åä½œä¸ºå¤‡ç”¨
        rank_in_all = max(1, int(total_papers * (1 - final_probability)))
        rank_in_accepted = max(1, int(accepted_papers_count * (1 - final_probability)))

    result = {
        "probability": final_probability,
        "rank_in_all": rank_in_all,
        "rank_in_accepted": rank_in_accepted,
        "total_papers": total_papers,
        "accepted_papers": accepted_papers_count,
        "prediction_method": "rule_threshold_with_historical_ranking"
    }

    print(f"ğŸ¯ æœ€ç»ˆç»“æœ: {result}")
    return result


def load_settings():
    """åŠ è½½è®¾ç½®"""
    try:
        if os.path.exists(SETTINGS_FILE):
            with open(SETTINGS_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
    except Exception as e:
        print(f"åŠ è½½è®¾ç½®å¤±è´¥: {e}")
    return DEFAULT_SETTINGS.copy()


def save_settings(settings):
    """ä¿å­˜è®¾ç½®"""
    try:
        with open(SETTINGS_FILE, 'w', encoding='utf-8') as f:
            json.dump(settings, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"ä¿å­˜è®¾ç½®å¤±è´¥: {e}")
        return False


def load_payments():
    """åŠ è½½æ”¯ä»˜è®°å½•"""
    global payments
    try:
        if os.path.exists(PAYMENTS_FILE):
            with open(PAYMENTS_FILE, 'r', encoding='utf-8') as f:
                payments = json.load(f)
    except Exception as e:
        print(f"åŠ è½½æ”¯ä»˜è®°å½•å¤±è´¥: {e}")
        payments = {}


def save_payments():
    """ä¿å­˜æ”¯ä»˜è®°å½•"""
    try:
        with open(PAYMENTS_FILE, 'w', encoding='utf-8') as f:
            json.dump(payments, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"ä¿å­˜æ”¯ä»˜è®°å½•å¤±è´¥: {e}")
        return False


# å¯åŠ¨æ—¶åŠ è½½æ•°æ®
current_settings = load_settings()
load_payments()
download_data_from_google_drive()  # ğŸ”¥ æ·»åŠ è¿™è¡Œ
load_historical_data()  # åŠ è½½å†å²æ•°æ®


# æ•°æ®æ¨¡å‹
class PredictionRequest(BaseModel):
    scores: List[float]
    confidences: List[float] = []
    conference: str = "ICLR"


class PredictionResponse(BaseModel):
    probability: float
    rank_in_all: int
    rank_in_accepted: int
    avg_score: float
    min_score: float
    total_papers: int
    accepted_papers: int
    prediction_method: str = "rule_threshold"
    prediction_time_ms: Optional[int] = None


class SettingsUpdate(BaseModel):
    price: float
    contact_phone: str
    score_options: str
    confidence_options: str
    conference: Optional[str] = "ICLR"
    year: Optional[str] = "2024"
    payment_wait_time: Optional[int] = 60  # æ–°å¢ï¼šæ”¯ä»˜ç­‰å¾…æ—¶é—´


class PaymentOrder(BaseModel):
    amount: float
    description: str


class PaymentResponse(BaseModel):
    orderId: str
    amount: float
    status: str = "pending"


@app.get("/")
async def root():
    return {
        "message": "è®ºæ–‡æ¥å—ç‡é¢„æµ‹APIæ­£åœ¨è¿è¡Œ",
        "version": "2.0.0",
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "features": {
            "ml_models": False,
            "prediction_method": "rule_based",
            "prediction_stats": prediction_stats,
            "historical_data_loaded": list(historical_data.keys())  # ä¿®å¤ï¼šè¿”å›å·²åŠ è½½çš„æ•°æ®å¹´ä»½
        }
    }


@app.get("/settings")
async def get_settings():
    """è·å–å½“å‰è®¾ç½®"""
    return current_settings


@app.post("/settings")
async def update_settings(new_settings: SettingsUpdate):
    """æ›´æ–°è®¾ç½®"""
    global current_settings

    try:
        # è§£æè¯„åˆ†é€‰é¡¹
        score_options = [float(x.strip()) for x in new_settings.score_options.split(',') if x.strip()]
        confidence_options = [float(x.strip()) for x in new_settings.confidence_options.split(',') if x.strip()]
        # æ›´æ–°è®¾ç½®
        current_settings.update({
            "price": new_settings.price,
            "contact_phone": new_settings.contact_phone,
            "score_options": score_options,
            "confidence_options": confidence_options,
            "conference": new_settings.conference or current_settings.get("conference", "ICLR"),
            "year": new_settings.year or current_settings.get("year", "2024"),
            "payment_wait_time": new_settings.payment_wait_time or current_settings.get("payment_wait_time", 60)
        })

        # ä¿å­˜åˆ°æ–‡ä»¶
        success = save_settings(current_settings)

        if success:
            return {"message": "è®¾ç½®å·²æ›´æ–°", "settings": current_settings}
        else:
            raise HTTPException(status_code=500, detail="ä¿å­˜è®¾ç½®å¤±è´¥")

    except ValueError as e:
        raise HTTPException(status_code=400, detail="è¯„åˆ†é€‰é¡¹æ ¼å¼é”™è¯¯")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ›´æ–°è®¾ç½®å¤±è´¥: {str(e)}")


@app.post("/upload-qr")
async def upload_qr_code(file: UploadFile = File(...)):
    """ä¸Šä¼ æ”¯ä»˜äºŒç»´ç """
    try:
        # éªŒè¯æ–‡ä»¶ç±»å‹
        if not file.content_type.startswith('image/'):
            raise HTTPException(status_code=400, detail="è¯·ä¸Šä¼ å›¾ç‰‡æ–‡ä»¶")

        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
        file_extension = os.path.splitext(file.filename)[1]
        unique_filename = f"qr_{int(time.time())}{file_extension}"
        file_path = f"uploads/qr_codes/{unique_filename}"

        # ä¿å­˜æ–‡ä»¶
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)

        # æ›´æ–°è®¾ç½®ä¸­çš„äºŒç»´ç URL
        qr_url = f"/uploads/qr_codes/{unique_filename}"
        current_settings["qr_code_url"] = qr_url
        save_settings(current_settings)

        return {"qr_code_url": qr_url, "message": "äºŒç»´ç ä¸Šä¼ æˆåŠŸ"}

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ä¸Šä¼ å¤±è´¥: {str(e)}")


@app.post("/create-payment", response_model=PaymentResponse)
async def create_payment_order(order: PaymentOrder):
    """åˆ›å»ºæ”¯ä»˜è®¢å•"""
    try:
        order_id = str(uuid.uuid4())
        payment_data = {
            "orderId": order_id,
            "amount": order.amount,
            "description": order.description,
            "status": "pending",
            "created_at": datetime.now().isoformat(),
            "expires_at": datetime.fromtimestamp(time.time() + 1800).isoformat()  # 30åˆ†é’Ÿåè¿‡æœŸ
        }

        # ä¿å­˜è®¢å•
        payments[order_id] = payment_data
        save_payments()

        return PaymentResponse(
            orderId=order_id,
            amount=order.amount,
            status="pending"
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºæ”¯ä»˜è®¢å•å¤±è´¥: {str(e)}")


@app.get("/check-payment/{order_id}")
async def check_payment_status(order_id: str):
    """æ£€æŸ¥æ”¯ä»˜çŠ¶æ€"""
    if order_id not in payments:
        raise HTTPException(status_code=404, detail="è®¢å•ä¸å­˜åœ¨")

    payment = payments[order_id]

    # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
    expires_at = datetime.fromisoformat(payment["expires_at"])
    if datetime.now() > expires_at:
        payment["status"] = "expired"
        payments[order_id] = payment
        save_payments()

    # æ¨¡æ‹Ÿæ”¯ä»˜æˆåŠŸæ¦‚ç‡ï¼ˆå®é™…åº”è¯¥è°ƒç”¨çœŸå®æ”¯ä»˜APIï¼‰
    created_at = datetime.fromisoformat(payment["created_at"])
    elapsed = (datetime.now() - created_at).total_seconds()

    if elapsed > 10 and payment["status"] == "pending":
        import random
        if random.random() < 0.8:  # 80%æ¦‚ç‡æˆåŠŸ
            payment["status"] = "success"
            payment["paid_at"] = datetime.now().isoformat()
        else:
            payment["status"] = "failed"

        payments[order_id] = payment
        save_payments()

    return {"status": payment["status"], "order_id": order_id}


@app.post("/predict", response_model=PredictionResponse)
async def predict(request: PredictionRequest):
    """é¢„æµ‹è®ºæ–‡æ¥å—ç‡"""
    print(f"\nğŸš€ æ”¶åˆ°é¢„æµ‹è¯·æ±‚: {request}")

    if not request.scores:
        raise HTTPException(status_code=400, detail="è¯·æä¾›è¯„åˆ†")

    try:
        start_time = time.time()

        # åŸºæœ¬ç»Ÿè®¡
        avg_score = np.mean(request.scores)
        min_score = min(request.scores)

        print(f"ğŸ“Š åŸºæœ¬ç»Ÿè®¡ - å¹³å‡åˆ†: {avg_score:.2f}, æœ€ä½åˆ†: {min_score}")

        # ä½¿ç”¨åŸºç¡€è§„åˆ™è®¡ç®—æ’åï¼Œä¼ é€’å¹´ä»½ä¿¡æ¯
        year = current_settings.get("year", "2025")
        ranking_result = calculate_paper_ranking_basic(request.scores, request.confidences, year)

        # è®¡ç®—é¢„æµ‹æ—¶é—´
        prediction_time = time.time() - start_time
        prediction_stats["total_predictions"] += 1
        prediction_stats["avg_prediction_time"] = (
                                                          prediction_stats["avg_prediction_time"] * (
                                                          prediction_stats["total_predictions"] - 1) +
                                                          prediction_time
                                                  ) / prediction_stats["total_predictions"]

        response = PredictionResponse(
            probability=ranking_result["probability"],
            rank_in_all=ranking_result["rank_in_all"],
            rank_in_accepted=ranking_result["rank_in_accepted"],
            avg_score=avg_score,
            min_score=min_score,
            total_papers=ranking_result["total_papers"],
            accepted_papers=ranking_result["accepted_papers"],
            prediction_method=ranking_result["prediction_method"],
            prediction_time_ms=int(prediction_time * 1000)
        )

        print(f"âœ… é¢„æµ‹å®Œæˆ: æ¦‚ç‡={response.probability:.3f}, ç”¨æ—¶={response.prediction_time_ms}ms")
        return response

    except Exception as e:
        print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"é¢„æµ‹å¤±è´¥: {str(e)}")


@app.get("/data-status")
async def get_data_status():
    """è·å–æ•°æ®åŠ è½½çŠ¶æ€"""
    return {
        "historical_data_loaded": list(historical_data.keys()),
        "data_details": {
            year: {
                "total_papers": data["total_count"],
                "accepted_papers": data["accepted_count"],
                "acceptance_rate": f"{data['acceptance_rate']:.2%}"
            }
            for year, data in historical_data.items()
        },
        "prediction_method": "rule_based_with_historical_ranking"
    }


@app.get("/stats")
async def get_stats():
    """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
    try:
        # ç»Ÿè®¡æ”¯ä»˜è®°å½•
        total_orders = len(payments)
        successful_payments = sum(1 for p in payments.values() if p["status"] == "success")
        total_revenue = sum(p["amount"] for p in payments.values() if p["status"] == "success")

        # ä»Šæ—¥ç»Ÿè®¡
        today = datetime.now().date()
        today_orders = sum(1 for p in payments.values()
                           if datetime.fromisoformat(p["created_at"]).date() == today)
        today_revenue = sum(p["amount"] for p in payments.values()
                            if p["status"] == "success" and
                            datetime.fromisoformat(p["created_at"]).date() == today)

        return {
            "total_orders": total_orders,
            "successful_payments": successful_payments,
            "total_revenue": total_revenue,
            "today_orders": today_orders,
            "today_revenue": today_revenue,
            "success_rate": successful_payments / total_orders if total_orders > 0 else 0,
            "prediction_stats": prediction_stats,
            "prediction_method": "rule_based_only",
            "historical_data": {  # ä¿®å¤ï¼šæ·»åŠ å†å²æ•°æ®ä¿¡æ¯
                year: {
                    "total_papers": data["total_count"],
                    "accepted_papers": data["accepted_count"],
                    "acceptance_rate": data["acceptance_rate"]
                }
                for year, data in historical_data.items()
            }
        }
    except Exception as e:
        return {"error": f"è·å–ç»Ÿè®¡å¤±è´¥: {str(e)}"}


# ä¿®å¤3ï¼šæ·»åŠ å¥åº·æ£€æŸ¥ç«¯ç‚¹
@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "version": "2.0.0",
        "data_loaded": len(historical_data) > 0,
        "historical_years": list(historical_data.keys())
    }


if __name__ == "__main__":
    import os

    port = int(os.environ.get("PORT", 8000))

    print("ğŸš€ å¯åŠ¨è®ºæ–‡æ¥å—ç‡é¢„æµ‹API...")
    print("âœ¨ ç‰¹æ€§:")
    print("  - åŸºäºè§„åˆ™çš„é¢„æµ‹ç®—æ³•")
    print("  - å†å²æ•°æ®æ”¯æŒæ’åè®¡ç®—")
    print("  - è¯¦ç»†çš„è°ƒè¯•æ—¥å¿—")
    print("  - ä¿®å¤äº†CORSå’Œç§»åŠ¨ç«¯é€‚é…")
    print("  - å¯é…ç½®æ”¯ä»˜ç­‰å¾…æ—¶é—´")
    print("")
    print("ğŸŒ è®¿é—®åœ°å€:")
    print(f"  APIæœåŠ¡: http://0.0.0.0:{port}")
    print(f"  APIæ–‡æ¡£: http://0.0.0.0:{port}/docs")
    print(f"  æ•°æ®çŠ¶æ€: http://0.0.0.0:{port}/data-status")
    print(f"  å¥åº·æ£€æŸ¥: http://0.0.0.0:{port}/health")
    print(f"  ç³»ç»Ÿç»Ÿè®¡: http://0.0.0.0:{port}/stats")

    uvicorn.run(app, host="0.0.0.0", port=port)